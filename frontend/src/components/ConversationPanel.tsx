import React, { useState, useEffect, useRef } from 'react';
import Message from './Message'; // Message ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸

interface MessageData {
  type: 'paramedic' | 'ai' | 'system';
  content: string;
  sender?: string;
  timestamp: string;
}

// ë°±ì—”ë“œë¡œ ì „ì†¡í•  ë©”ì‹œì§€ í˜•ì‹ (roleê³¼ contentë§Œ í¬í•¨)
interface BackendMessage {
    role: 'system' | 'user' | 'assistant';
    content: string;
}

interface ConversationPanelProps {
  isInitialized: boolean;
  initializeSystem: () => Promise<void>;
  ragStatus: string;
  aiStatus: string;
  hospitalStatus: string;
  onUpdateStats: (newTurnCount: number, newConfidence: number) => void;
  onShowBriefing: () => void;
}

// Web Speech API íƒ€ì… ì •ì˜
interface SpeechRecognitionEvent extends Event {
  resultIndex: number;
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  isFinal: boolean;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  onresult: (event: SpeechRecognitionEvent) => void;
  start(): void;
  stop(): void;
}

interface SpeechRecognitionConstructor {
  new (): SpeechRecognition;
  prototype: SpeechRecognition;
}

declare global {
  interface Window {
    SpeechRecognition: SpeechRecognitionConstructor;
    webkitSpeechRecognition: SpeechRecognitionConstructor;
  }
}

const ConversationPanel: React.FC<ConversationPanelProps> = ({
  isInitialized,
  initializeSystem,
  ragStatus,
  aiStatus,
  hospitalStatus,
  onUpdateStats,
  onShowBriefing,
}) => {
  const [messages, setMessages] = useState<MessageData[]>([]);
  const [userInput, setUserInput] = useState('');
  const [turnCount, setTurnCount] = useState(0);
  const [currentConfidence, setCurrentConfidence] = useState(0);
  const [isAILoading, setIsAILoading] = useState(false); // AI ì‘ë‹µ ëŒ€ê¸° ìƒíƒœ
  const [isRecording, setIsRecording] = useState(false); // ìŒì„± ë…¹ìŒ ìƒíƒœ ì¶”ê°€
  
  const conversationLogRef = useRef<HTMLDivElement>(null); // ìë™ ìŠ¤í¬ë¡¤ì„ ìœ„í•œ ref
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const [wsConnection, setWsConnection] = useState<WebSocket | null>(null);

  // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
  const systemPrompt: BackendMessage = {
      role: 'system',
      content: `You are an Emergency AI Agent designed to assist paramedics in managing medical emergencies.
Your goal is to gather critical information about the patient's condition and the emergency situation through a conversation with the paramedic.
Based on the information gathered, you should provide guidance, ask relevant follow-up questions, and eventually help determine if enough information has been collected for a hospital briefing.
Maintain a professional, calm, and informative tone. Focus on medically relevant details.
Avoid making definitive diagnoses or giving medical instructions that are outside the scope of assisting in information gathering.
Keep your responses concise and focused on obtaining necessary information or providing guidance based on gathered facts.
The conversation history will be provided in each turn. Use the previous messages to maintain context and avoid asking repetitive questions if the information has already been provided by the paramedic or yourself.
When you believe sufficient information has been gathered (e.g., after 4-5 turns or when key details like patient status, vital signs, injury type/location are known), indicate that a hospital briefing can be prepared.`,
  };

  // ì´ˆê¸°í™” ì™„ë£Œ ì‹œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
  useEffect(() => {
    if (isInitialized) {
      addMessage("system", "âœ… EmergencyAI ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ê¸‰ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.");
    }
  }, [isInitialized]);

  // ë©”ì‹œì§€ ì¶”ê°€ ë° ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    if (conversationLogRef.current) {
      conversationLogRef.current.scrollTop = conversationLogRef.current.scrollHeight;
    }
  }, [messages]);

  // í„´ ìˆ˜ ë˜ëŠ” í™•ì‹ ë„ ë³€ê²½ ì‹œ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ë¡œ ì „ë‹¬
  useEffect(() => {
      onUpdateStats(turnCount, currentConfidence); // turnCount ë˜ëŠ” currentConfidence ë³€ê²½ ì‹œ í˜¸ì¶œ
  }, [turnCount, currentConfidence, onUpdateStats]); // onUpdateStatsë„ ì˜ì¡´ì„± ë°°ì—´ì— í¬í•¨

  // WebSocket ì—°ê²° ì„¤ì •
  useEffect(() => {
    return () => {
      if (wsConnection) {
        wsConnection.close();
      }
    };
  }, [wsConnection]);

  const addMessage = (type: MessageData['type'], content: string, sender?: string) => {
    const timestamp = new Date().toLocaleTimeString();
    setMessages((prevMessages) => [...prevMessages, { type, content, sender, timestamp }]);
  };

  // ì‘ë‹µ ì œì¶œ í•¸ë“¤ëŸ¬
  const handleSubmit = async () => {
    // ì „ì†¡ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œ ìŒì„± ì¸ì‹ë„ ì¤‘ì§€
    stopRecognition();
    if (isRecording) {
      stopRecording();
      // stopRecordingì€ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë…¹ìŒì„ ì¤‘ì§€í•˜ë¯€ë¡œ, ì•½ê°„ì˜ ì§€ì—° í›„ ì „ì†¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.
      await new Promise(resolve => setTimeout(resolve, 300));
    }
    if (!userInput.trim()) {
      alert('ì‘ê¸‰ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      return;
    }

    if (!isInitialized) {
      alert('ì‹œìŠ¤í…œì„ ë¨¼ì € ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.');
      return;
    }
    
    setIsAILoading(true);

    const currentInput = userInput; // ìŠ¤ëƒ…ìƒ· ì €ì¥
    setUserInput(''); // ì „ì†¡ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œë§Œ ì…ë ¥ì°½ì„ ë¹„ì›€

    // ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¥¼ ë¨¼ì € ì¶”ê°€
    addMessage('paramedic', currentInput);

    // ë°±ì—”ë“œ API í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
    await processUserInput(currentInput);

    setIsAILoading(false);
  };

  // ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ë°±ì—”ë“œ APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ë¡œ ì—­í•  ë³€ê²½
  const processUserInput = async (input: string) => {
       // addMessage í˜¸ì¶œ í›„ ìƒíƒœê°€ ë°”ë¡œ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ,
       // í˜„ì¬ messages ìƒíƒœì™€ ìƒˆë¡œìš´ ì…ë ¥ì„ í•©ì³ì„œ ë°±ì—”ë“œë¡œ ë³´ë‚¼ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
       // ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ê°€ì¥ ì•ì— ì¶”ê°€í•©ë‹ˆë‹¤.
       const messagesToSend: BackendMessage[] = [
           systemPrompt, // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
           ...messages.map(msg => ({
               role: (msg.type === 'paramedic' ? 'user' : (msg.type === 'ai' ? 'assistant' : 'system')) as 'user' | 'assistant' | 'system', // ëª…ì‹œì ìœ¼ë¡œ íƒ€ì… ë‹¨ì–¸
               content: msg.content
           })),
           { role: 'user', content: input } // í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
       ];


      const nextTurnCount = turnCount + 1;
      setTurnCount(nextTurnCount);

      // í™•ì‹ ë„ ê³„ì‚° (í”„ë¡ íŠ¸ì—ì„œ ì„ì‹œ ê³„ì‚° ìœ ì§€)
      const nextConfidence = calculateConfidence(nextTurnCount);
      setCurrentConfidence(Math.round(nextConfidence * 100));


      addMessage("system", "ğŸ” AI ì‘ë‹µ ìƒì„± ì¤‘...");


      // ë°±ì—”ë“œ API í˜¸ì¶œ
      try {
          const response = await fetch('http://localhost:8000/chat', {
              method: 'POST',
              headers: {
                  'Content-Type': 'application/json',
              },
              body: JSON.stringify({ messages: messagesToSend }), // ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON bodyë¡œ ì „ì†¡
          });

          if (!response.ok) {
              throw new Error(`HTTP error! status: ${response.status}`);
          }

          const data = await response.json();
          const aiResponseContent = data.response; // ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •

          // AI ì‘ë‹µ ì¶”ê°€
          addMessage('ai', aiResponseContent, 'ğŸ¤– AI Emergency Alert');

          // ëŒ€í™” ì¢…ë£Œ ì—¬ë¶€ í™•ì¸
          if (data.should_end) {
              await new Promise(resolve => setTimeout(resolve, 1000));
              addMessage("system", "ğŸ“‹ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ë³‘ì› ë¸Œë¦¬í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.");
              onShowBriefing();
          }

      } catch (error: unknown) {
          console.error('Error fetching AI response:', error);
          const errorMessage = error instanceof Error ? error.message : String(error);
          addMessage("system", `âŒ AI ì‘ë‹µ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${errorMessage}`);
      }

      // TODO: updateLastUpdate() ë¡œì§ êµ¬í˜„ (ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì—ì„œ ê´€ë¦¬ë  ìˆ˜ë„ ìˆìŒ)
  };

  // --- ì‹œë®¬ë ˆì´ì…˜ìš© ê¸°ì¡´ JS í•¨ìˆ˜ë“¤ (í•„ìš”ì— ë”°ë¼ React ìƒíƒœ/props ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •) ---
  const checkEmergencyKeywords = (input: string) => {
      const emergencyKeywords = [
          'ì˜ì‹ìƒìŒ', 'ì˜ì‹ì—†ìŒ', 'ì‹¬ì •ì§€', 'í˜¸í¡ê³¤ë€', 'ëŒ€ëŸ‰ì¶œí˜ˆ', 'ì‡¼í¬',
          'êµí†µì‚¬ê³ ', 'ì¶”ë½', 'ì™¸ìƒ', 'ê³¨ì ˆ', 'ì‹¬ì¥í†µì¦', 'ê°€ìŠ´í†µì¦', 'ë‡Œì¡¸ì¤‘', 'ê²½ë ¨'
      ];
      
      return emergencyKeywords.some(keyword => input.includes(keyword));
  };

  const calculateConfidence = (currentTurn: number) => {
      const baseConfidence = 0.3;
      const turnBonus = currentTurn * 0.15; // í„´ë‹¹ í™•ì‹ ë„ ì¦ê°€ëŸ‰ ì¡°ì •
      // TODO: ìˆ˜ì§‘ëœ ì •ë³´ëŸ‰ ë°˜ì˜ ë¡œì§ ì¶”ê°€ í•„ìš”
      // const infoBonus = Object.keys(conversationState.collectedInfo).length * 0.1;
      
      return Math.min(baseConfidence + turnBonus /* + infoBonus*/, 0.95);
  };

  const getImmediateAction = (input: string) => {
      if (input.includes('ì˜ì‹ìƒìŒ') || input.includes('ì˜ì‹ì—†ìŒ')) {
          return "ê¸°ë„ í™•ë³´ ë° ê²½ì¶” ê³ ì •, GCS ì ìˆ˜ ì¸¡ì •";
      } else if (input.includes('í˜¸í¡ê³¤ë€')) {
          return "ì‚°ì†Œ ê³µê¸‰ 15L/min, ê¸°ë„ í™•ì¸";
      } else if (input.includes('ì‹¬ì¥') || input.includes('ê°€ìŠ´í†µì¦')) {
          return "12ìœ ë„ ì‹¬ì „ë„ ì¸¡ì •, ë‹ˆíŠ¸ë¡œê¸€ë¦¬ì„¸ë¦° íˆ¬ì—¬ ê³ ë ¤";
      } else if (input.includes('ì¶œí˜ˆ')) {
          return "ì§ì ‘ ì••ë°•ì§€í˜ˆ, í˜ˆì•• ì¸¡ì •, ìˆ˜ì•¡ ê³µê¸‰ ì¤€ë¹„";
      } else {
          return "ê¸°ë³¸ ìƒì²´ì§•í›„ ì¸¡ì • (í˜ˆì••, ë§¥ë°•, í˜¸í¡, ì²´ì˜¨)";
      }
  };

  const generateQuestions = (input: string, currentTurn: number) => {
      const allQuestions = [
          "í™˜ìì˜ ë‚˜ì´ì™€ ì„±ë³„ì„ ì •í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”",
          "GCS(Glasgow Coma Scale) ì ìˆ˜ë¥¼ ì¸¡ì •í•´ì£¼ì„¸ìš”",
          "ì–‘ìª½ ë™ê³µì˜ í¬ê¸°ì™€ ë¹› ë°˜ì‘ì„ í™•ì¸í•´ì£¼ì„¸ìš”",
          "í˜ˆì••, ë§¥ë°•, í˜¸í¡ìˆ˜ë¥¼ ì¸¡ì •í•´ì£¼ì„¸ìš”",
          "í™˜ìê°€ í†µì¦ì„ í˜¸ì†Œí•˜ëŠ” ë¶€ìœ„ê°€ ìˆë‚˜ìš”?",
          "ì•Œë ¤ì§„ ì•Œë ˆë¥´ê¸°ë‚˜ ë³µìš© ì¤‘ì¸ ì•½ë¬¼ì´ ìˆë‚˜ìš”?",
          "ì‚¬ê³  ë‹¹ì‹œ ìƒí™©ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
          "í˜„ì¬ í™˜ìì˜ ì˜ì‹ ìƒíƒœëŠ” ì–´ë–¤ê°€ìš”?",
          "í˜¸í¡ íŒ¨í„´ì´ ê·œì¹™ì ì¸ê°€ìš”?",
          "ëª©ì´ë‚˜ ì²™ì¶” ë¶€ìœ„ì— ì†ìƒ ì§•í›„ê°€ ë³´ì´ë‚˜ìš”?"
      ];

      // í„´ì— ë”°ë¼ ë‹¤ë¥¸ ì§ˆë¬¸ ë°˜í™˜
      const startIndex = (currentTurn - 1) * 3;
      return allQuestions.slice(startIndex, startIndex + 3);
  };

  const shouldEndConversation = (currentTurn: number, confidence: number) => {
      return currentTurn >= 4 || confidence >= 0.9; // ì¢…ë£Œ ì¡°ê±´ ì•½ê°„ ë³€ê²½
  };
  
  // TODO: showBriefingScreen í•¨ìˆ˜ (propìœ¼ë¡œ ì „ë‹¬ë°›ê±°ë‚˜ ì´ ì»´í¬ë„ŒíŠ¸ì—ì„œ ë¼ìš°íŒ… ì²˜ë¦¬)

  // Web Speech API (ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë³€í™˜)
  const startRecognition = () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) return;
    const recognition = new SpeechRecognition();
    recognition.lang = 'ko-KR';
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let fullTranscript = '';
      for (let i = 0; i < event.results.length; ++i) {
        fullTranscript += event.results[i][0].transcript;
      }
      setUserInput(fullTranscript);
    };
    recognitionRef.current = recognition;
    recognition.start();
  };

  const stopRecognition = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
  };

  // ìŒì„± ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      setUserInput(''); // ì…ë ¥ì°½ ì´ˆê¸°í™”
      audioChunksRef.current = []; // ì˜¤ë””ì˜¤ ì²­í¬ ì´ˆê¸°í™”
      
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);

      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };

      recorder.start();
      mediaRecorderRef.current = recorder;
      setIsRecording(true);
      addMessage("system", "ğŸ¤ ìŒì„± ë…¹ìŒ ì¤‘...");
      
      // ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘
      startRecognition();
    } catch (error) {
      console.error('Error accessing microphone:', error);
      addMessage("system", "âŒ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
    }
  };

  // ìŒì„± ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      setIsRecording(false);
      addMessage("system", "ğŸ” ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...");
      
      // ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì¤‘ì§€
      stopRecognition();
      
      // ë…¹ìŒëœ ìŒì„±ì„ Whisperë¡œ ì²˜ë¦¬
      if (audioChunksRef.current.length > 0) {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        convertSpeechToText(audioBlob);
      }
    }
  };

  // ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Whisper ì‚¬ìš©)
  const convertSpeechToText = async (audioBlob: Blob) => {
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      const response = await fetch('http://localhost:8000/transcribe', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error('ìŒì„± ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }

      const data = await response.json();
      if (data.error) {
        throw new Error(data.error);
      }
      
      // ì…ë ¥ì°½ì— ë³€í™˜ëœ í…ìŠ¤íŠ¸ í‘œì‹œ
      setUserInput(data.text);
    } catch (error) {
      console.error('Error converting speech to text:', error);
      addMessage("system", "âŒ ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
    }
  };

  return (
    <div className="conversation-panel">
      {!isInitialized ? (
        // ì´ˆê¸°í™” í™”ë©´
        <div className="initialization-screen">
          <h2>EmergencyAI ì‹œìŠ¤í…œ ì´ˆê¸°í™”</h2>
          <p>ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ AI ì—”ì§„ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.</p>

          {/* ì§„í–‰ ë°” (ë‚˜ì¤‘ì— êµ¬í˜„) */}
          {/* <div className="progress-container">...</div> */}

          <button
            className="init-button"
            onClick={initializeSystem}
            disabled={false}
          >
            ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘
          </button>

          <div style={{ marginTop: '30px' }}>
            <h3>ğŸ¯ ì‹œìŠ¤í…œ êµ¬ì„±</h3>
            <ul style={{ textAlign: 'left', maxWidth: '500px', margin: '15px auto' }}>
              <li>ğŸ“š ì˜í•™ ë¬¸ì„œ 5,000+ ê°œ (PubMed, AHA, ATLS)</li>
              <li>ğŸ§  Upstage Solar LLM ì—°ë™</li>
              <li>ğŸ” ê³„ì¸µì  RAG ê²€ìƒ‰ ì—”ì§„</li>
              <li>ğŸ¥ ë³‘ì› ì—°ë™ ì‹œìŠ¤í…œ</li>
            </ul>
          </div>
        </div>
      ) : (
        // ì´ˆê¸°í™” ì™„ë£Œ í›„ ëŒ€í™” ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
        <div className="conversation-interface">
          <h2>ğŸ’¬ ì‘ê¸‰ìƒí™© ëŒ€í™”</h2>

          {/* ëŒ€í™” ë¡œê·¸ */}
          <div className="conversation-log" ref={conversationLogRef}>
            {messages.map((msg, index) => (
              <Message
                key={index}
                type={msg.type}
                content={msg.content}
                sender={msg.sender}
                timestamp={msg.timestamp}
              />
            ))}
          </div>

          {/* ì…ë ¥ ì„¹ì…˜ */}
          <div className="input-section">
            <h3>ğŸ¤ ì‘ê¸‰êµ¬ì¡°ì‚¬ë‹˜, í˜„ì¬ ìƒí™©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”</h3>
            <div className="input-group">
              <label htmlFor="userInput">ìƒí™© ì„¤ëª…:</label>
              <textarea
                id="userInput"
                placeholder="ì˜ˆ: êµí†µì‚¬ê³ , 20ëŒ€ ë‚¨ì„±, ì˜ì‹ ìƒìŒ"
                value={userInput}
                onChange={(e) => setUserInput(e.target.value)}
                onKeyPress={(e) => {
                  if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    handleSubmit();
                  }
                }}
                disabled={isAILoading}
              ></textarea>
            </div>
            <div className="button-group">
              <button 
                className={`mic-button ${isRecording ? 'recording' : ''}`} 
                onClick={isRecording ? stopRecording : startRecording}
                disabled={isAILoading}
              >
                {isRecording ? 'â¹ï¸ ë…¹ìŒ ì¤‘ì§€' : 'ğŸ¤ ìŒì„± ì…ë ¥'}
              </button>
              <button 
                className="submit-button" 
                onClick={handleSubmit} 
                disabled={isAILoading}
              >
                {isAILoading ? <div className="loading-spinner"></div> : 'ì „ì†¡'}
              </button>
            </div>
          </div>
        </div>
        // TODO: ë¸Œë¦¬í•‘ í™”ë©´ (briefing-screen) ì¡°ê±´ë¶€ ë Œë”ë§ ì¶”ê°€
      )}
    </div>
  );
};

export default ConversationPanel; 